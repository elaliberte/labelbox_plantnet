# ğŸŒ¿ Labelbox Ã— Pl\@ntNet â€” Brazilian Amazon Trees

<table>
  <tr>
    <th align="center">Classification</th>
    <th align="center">Boxes</th>
    <th align="center">Masks</th>
  </tr>
  <tr>
    <td align="center"><img src="media/class.jpg" alt="Classification" width="300"/></td>
    <td align="center"><img src="media/boxes.jpg" alt="Boxes" width="300"/></td>
    <td align="center"><img src="media/masks.jpg" alt="Masks" width="300"/></td>
  </tr>
</table>

Integrating [Pl\@ntNet](https://plantnet.org) multi-species predictions with [Labelbox](https://labelbox.com) for model-assisted labelling of ultra high-resolution drone close-up photos of tropical trees (Brazilian Amazon).

Three annotation workflows are demonstrated:

| Workflow | Annotation type | Active learning? | Script folder |
|:---|:---|:---|:---|
| ğŸ¯ **Classification** | Global Radio | âœ… Yes (confidence works) | `scripts/04a_class/` |
| ğŸ“¦ **Boxes** | `BBOX` + nested Radio | âœ… Yes (confidence works) | `scripts/04b_boxes/` |
| ğŸ­ **Masks** | `RASTER_SEGMENTATION` + nested Radio | âš ï¸ Confidence stored but UI filter broken | `scripts/04c_masks/` |

Pl\@ntNet micro-project used: [Trees of the Brazilian Amazon](https://identify.plantnet.org/xprize-final-trees/species) (\~2 464 taxa).

------------------------------------------------------------------------

## ğŸ’» Prerequisites

-   **Python 3.10+** (tested with 3.13)
-   **Git** installed ([git-scm.com](https://git-scm.com))
-   A **Pl\@ntNet API key** â†’ [my.plantnet.org](https://my.plantnet.org)
-   A **Labelbox API key** â†’ [app.labelbox.com](https://app.labelbox.com) â†’ Settings â†’ API Keys


------------------------------------------------------------------------

## âš™ï¸ Setup

### 1. Clone this repo

``` bash
git clone https://github.com/YOUR_USERNAME/labelbox_plantnet.git
cd labelbox_plantnet
```

### 2. Create a virtual environment

``` bash
python -m venv .venv
```

### 3. Activate the virtual environment

**Windows (PowerShell):**

``` powershell
.venv\Scripts\Activate.ps1
```

**Windows (CMD):**

``` cmd
.venv\Scripts\activate.bat
```

**macOS / Linux:**

``` bash
source .venv/bin/activate
```

### 4. Install dependencies

``` bash
pip install -r requirements.txt
```

### 5. Set up your API keys

Copy the example file:

``` bash
copy .env.example .env
```

Then open `.env` in a text editor and paste your real keys:

``` bash
PLANTNET_API_KEY=your-plantnet-api-key-here
LABELBOX_API_KEY=your-labelbox-api-key-here
```

> âš ï¸ **Never commit `.env`** â€” it is already in `.gitignore`.

### 6. Add your drone images

Place your `.JPG` drone photos in the `images/` folder:

``` bash
images/
DJI_20250405090025_0008_V_121zoom.JPG
DJI_20250405090425_0018_V_93zoom.JPG
```


------------------------------------------------------------------------

## ğŸƒ How to run â€” step by step

All commands assume you are in the project root (`labelbox_plantnet/`) with the virtual environment activated.

The pipeline is split into **shared steps** (fetch species, upload images, get Pl\@ntNet predictions) followed by **workflow-specific steps** (classification, boxes, masks). The shared steps only need to be run once; the three workflows can then be run independently.

> âš ï¸ All parameters are paths are configurable in `config.yaml`. The provided scripts use the default paths as shown in the outputs below.

### ğŸŒ± Step 1 â€” Fetch species list from Pl\@ntNet

Downloads the \~2 464 species (scientific names + GBIF IDs) from the "Trees of the Brazilian Amazon" micro-project. This is a **shared** step â€” the species list is used by all three workflows.

```bash
python scripts/01_species/01_fetch_species.py
```

**Output**: `output/species/species_raw.json, output/species/species_list.csv`

### ğŸ–¼ï¸ Step 2 â€” Upload images to Labelbox

Creates a Labelbox dataset and uploads all images from the images/ folder. This is a shared step â€” the same dataset is reused by all three workflows.

``` bash
python scripts/02_images/02_upload_images.py
```

**Output**: `output/images/dataset_id.txt, output/images/upload_summary.json`

### ğŸ”® Step 3 â€” Run Pl\@ntNet predictions

Two prediction scripts are available:

#### 3a. Single-species predictions (Classification workflow):

Runs the standard Pl\@ntNet identify endpoint on each image, returning the single best species prediction per image, with confidence score. This is used in the Classification workflow as a global image-level label.

``` bash
python scripts/03_predictions/03a_single_predict.py
```

**Output**: `output/predictions/single_predictions.json`

#### 3b. Multi-species survey predictions (Boxes and Masks workflows):

Runs the multi-species (i.e. survey) endpoint, which breaks each image into tiles and returns the best species prediction + confidence score for each tile. This is used in the Boxes and Masks workflows to create more granular annotations.

``` bash
`python scripts/03_predictions/03b_multi_predict.py`
```

**Output**: `output/predictions/multi_predictions.json`

> âš ï¸ The multi-species survey endpoint can be expensive in API credits. The script displays a cost estimate before proceeding.

### ğŸ¯ Step 4a â€” Classification workflow

Uses **single-species predictions** â€” each image gets a single global label with the top predicted species. This can be useful for active learning to prioritize human review of low-confidence images.

#### 4a.1 â€” Create the classification ontology

The classification ontology uses a single `Radio` tool with one class per species (2 464 classes in this example).

``` bash
python scripts/04a_class/04_create_ontology.py`
```

**Output:** `output/class/ontology_id.txt`

#### 4a.2 â€” Create the classification project

Creates an empty labelling classification project to classify individual imnages to its most likely species.

``` bash
python scripts/04a_class/05_create_project.py
```

**Output:** `output/class/project_id.txt`

#### 4a.3 â€” Import classification predictions into a Model Run

Imports the single-species Pl\@ntNet predictions as a Model Run in Labelbox, associating each image with its predicted species label and confidence score.

``` bash
python scripts/04a_class/06_import_predictions.py
```

> âš ï¸ To send batchs to the labelling project, consult the [documentation](https://docs.labelbox.com/docs/model-run-batches).

**Output:** `output/class/model_run_id.txt`, `output/class/model_run_summary.json`

### ğŸ“¦ Step 4b â€” Bounding box workflow

Uses **multi-species survey predictions** â€” each species tile becomes a bounding box with a nested species Radio classification.

#### 4b.1 â€” Create the bounding box ontology

The bounding box ontology uses a `BBOX` tool to delineate species in the image, with a nested `Radio` for species classification (2 464 classes in this example).

``` bash
python scripts/04b_boxes/04_create_ontology.py
```

**Output:** `output/boxes/ontology_id.txt`

#### 4b.2 â€” Create the bounding box project

Creates an empty labelling bounding box project to delineate species in the image.

``` bash
python scripts/04b_boxes/05_create_project.py
```

**Output:** `output/boxes/project_id.txt`

#### 4b.3 â€” Import box predictions into a Model Run

Imports the multi-species Pl\@ntNet predictions as a Model Run in Labelbox, selecting for each species predicted in an image the single tile with the highest confidence score.

``` bash
python scripts/04b_boxes/06_import_predictions.py
```

**Output:** `output/boxes/model_run_id.txt`, `output/boxes/model_run_summary.json`

### ğŸ­ Step 4c â€” Segmentation mask workflow

Uses **multi-species survey predictions** â€” each species' best tile is painted onto a composite mask image with a unique color per species. These are made from box predictions but overlapping regions keep only the species with the highest confidence.

#### 4c.1 â€” Create the segmentation ontology

The segmentation mask ontology uses a `RASTER_SEGMENTATION` tool with one class per species.

``` bash
python scripts/04c_masks/04_create_ontology.py
```

**Output:** `output/masks/ontology_id.txt`

#### 4c.2 â€” Create the segmentation project

Creates an empty labelling segmentation project to delineate species in the image with masks.

``` bash
python scripts/04c_masks/05_create_project.py
```

**Output:** `output/masks/project_id.txt`

#### 4c.3 â€” Import mask predictions into a Model Run

Imports the multi-species Pl\@ntNet predictions as a Model Run in Labelbox, creating composite mask images for each photo where each pixel is assigned to the species with the highest confidence prediction for that pixel's tile.

> âš ï¸ Mask uploads are slow due to large PNG files (4000Ã—3000 px). Expect a few minutes.

``` bash
python scripts/04c_masks/06_import_predictions.py
```

**Output:** `output/masks/model_run_id.txt`, `output/masks/model_run_summary.json`, `output/masks/composite_masks/*.png`

------------------------------------------------------------------------

## ğŸ—ï¸ Project structure

```         
labelbox_plantnet/
â”œâ”€â”€ .env.example              # Template for API keys
â”œâ”€â”€ .env                      # Your actual API keys (git-ignored)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ config.yaml               # Central pipeline configuration
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ images/                   # Your drone photos (git-ignored)
â”‚   â””â”€â”€ *.JPG
â”œâ”€â”€ media/                    # Screenshots for README
â”‚   â”œâ”€â”€ class.jpg
â”‚   â”œâ”€â”€ boxes.jpg
â”‚   â””â”€â”€ masks.jpg
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 01_species/           # Shared: fetch species list
â”‚   â”‚   â””â”€â”€ 01_fetch_species.py
â”‚   â”œâ”€â”€ 02_images/            # Shared: upload images to Labelbox
â”‚   â”‚   â””â”€â”€ 02_upload_images.py
â”‚   â”œâ”€â”€ 03_predictions/       # Shared: run Pl@ntNet predictions
â”‚   â”‚   â”œâ”€â”€ 03a_single_predict.py
â”‚   â”‚   â””â”€â”€ 03b_multi_predict.py
â”‚   â”œâ”€â”€ 04a_class/            # Classification workflow
â”‚   â”‚   â”œâ”€â”€ 04_create_ontology.py
â”‚   â”‚   â”œâ”€â”€ 05_create_project.py
â”‚   â”‚   â””â”€â”€ 06_import_predictions.py
â”‚   â”œâ”€â”€ 04b_boxes/            # Bounding box workflow
â”‚   â”‚   â”œâ”€â”€ 04_create_ontology.py
â”‚   â”‚   â”œâ”€â”€ 05_create_project.py
â”‚   â”‚   â””â”€â”€ 06_import_predictions.py
â”‚   â””â”€â”€ 04c_masks/            # Segmentation mask workflow
â”‚       â”œâ”€â”€ 04_create_ontology.py
â”‚       â”œâ”€â”€ 05_create_project.py
â”‚       â””â”€â”€ 06_import_predictions.py
â””â”€â”€ output/                   # Generated files (git-ignored except .gitkeep)
    â”œâ”€â”€ species/              # species_raw.json, species_list.csv
    â”œâ”€â”€ images/               # dataset_id.txt, upload_summary.json
    â”œâ”€â”€ predictions/          # single_predictions.json, multi_predictions.json
    â”œâ”€â”€ class/                # ontology_id.txt, project_id.txt, model_run_id.txt
    â”œâ”€â”€ boxes/                # ontology_id.txt, project_id.txt, model_run_id.txt
    â””â”€â”€ masks/                # ontology_id.txt, project_id.txt, model_run_id.txt, composite_masks/
```

------------------------------------------------------------------------

## ğŸš« Known limitations

-   **Confidence threshold slider does not filter segmentation masks** in the Labelbox Model Run gallery view. Confidence scores are stored correctly in the nested classification (i.e. species predictions) but not at the tool (mask) level, such that the UI slider has no effect on mask predictions. This works correctly for bounding boxes and classification.

-   **Max 4 000 classes per ontology** â€” the 2 464 taxa from the Brazilian Amazon micro-project fits within this limit, but the full Pl\@ntNet global flora (82K species) would not.

------------------------------------------------------------------------

## ğŸ”— Useful links

-   [Pl\@ntNet API â€” Single species](https://my.plantnet.org/doc/api/identify)

-   [Pl\@ntNet API â€” Survey (multi-species)](https://my.plantnet.org/doc/api/survey)

-   [Labelbox â€” Image editor & ontology](https://docs.labelbox.com/docs/image-editor#set-up-an-ontology)

-   [Labelbox â€” Upload image predictions](https://docs.labelbox.com/reference/upload-image-predictions)

-   [Labelbox â€” Active learning](https://docs.labelbox.com/docs/active-learning)

-   [Labelbox â€” Limits (4K classes)](https://docs.labelbox.com/docs/limits)